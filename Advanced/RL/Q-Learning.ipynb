{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitcbedb950e51a4bebb536402726991d1a",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "from pprint import pprint\n",
    "from Core.maze import Maze, INF\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGBA size=170x170 at 0x7F6420359730>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKoAAACqCAYAAAA9dtSCAAACN0lEQVR4nO3duwrCQBRF0Rnx/385VhY+AkLQzMa1Oq0Etyd2d44xtgGLu5z9AeATQiVBqCRcn9/YNn9ZOd+c8+G1RSXhZVHvnouGX9h7oltUEoRKglBJECoJQiVBqCQIlQShkiBUEoRKglBJECoJQiVBqCQIlQShkiBUEoRKglBJECoJQiVBqCQIlQShkiBUEoRKglBJECoJQiVBqCQIlQShkiBUEoRKglBJECoJQiVh9yrKqu5XM1a92uJO13dYVBJyi7q6VZe+wp0p0oRKglBJECoJQiVBqCQIlQShkiBUEoRKglBJECoJQiVBqCQIlQShkiBUEoRKglBJECoJQiVBqCQIlQShkiBUEoRKglBJECoJQiVBqCQIlQShkiBUEoRKglBJECoJQiUhexXFPadjatdbLCoJuUWtLcFqqk8ii0qCUEkQKglCJUGoJAiVBKGSIFQShEqCUEkQKglCJUGoJAiVBKGSIFQShEqCUEkQKglCJUGoJAiVBKGSIFQShEqCUEkQKglCJUGoJAiVBKGSIFQShEqCUEkQKglCJUGoJOSuolSvenCMRSUht6juTB1TfSJZVBKESoJQSRAqCUIlQagkCJUEoZIgVBKESoJQSRAqCUIlQagkCJUEoZIgVBKESoJQSRAqCUIlQagkCJUEoZIgVBKESoJQSRAqCUIlQagkCJUEoZIgVBKESoJQSRAqCUIlYfcqSvV6Bp+pfb8WleW8O9E0xxitnxZ/yaKSIFQShErCDRvDJFo8pSWUAAAAAElFTkSuQmCC\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "maze = Maze()\n",
    "N = 4\n",
    "maze.load(f\"BinaryTree_{N}x{N}.maze\")\n",
    "display(maze.draw(cell_width=40))"
   ]
  },
  {
   "source": [
    "# Q Learning\n",
    "add some basic intro "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT = 0.90"
   ]
  },
  {
   "source": [
    "## Reward\n",
    "on reaching the end, we give the agent 0 reward, else, its -1 for every timestep"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_cell(state):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        state:\n",
    "            the mapping to the linearised q-table index\n",
    "    return:\n",
    "        cell:\n",
    "            tuple of indices\n",
    "    \"\"\"\n",
    "    if not (0 <= state < N*N):\n",
    "        return None\n",
    "    quotient = state//maze.num_rows\n",
    "    remainder = state - quotient * maze.num_rows\n",
    "    return (quotient, remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_to_state(cell):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        cell:\n",
    "            tuple of indices\n",
    "    return:\n",
    "        state:\n",
    "            the mapping to the linearised q-table index\n",
    "    \"\"\"\n",
    "    if not (0 <= cell[0] < maze.num_rows and 0 <= cell[1] < maze.num_columns):\n",
    "        return None\n",
    "    return cell[0]*maze.num_rows + cell[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_cell(cell):\n",
    "    \"\"\"\n",
    "    takes input as current cell.\n",
    "\n",
    "    returns 0 if cell is the end state, else -1\n",
    "    \"\"\"\n",
    "\n",
    "    if cell[0] == maze.num_rows - 1 and cell[1] == maze.num_columns - 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(state):\n",
    "    \"\"\"\n",
    "    takes input as current state.\n",
    "    uses reward(cell)\n",
    "    returns 0 if cell is the end state, else -1\n",
    "    \"\"\"\n",
    "    return reward_cell(state_to_cell(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_cell(current_cell, action):\n",
    "    \"\"\"\n",
    "    TODO: RESTRICT THE ACTION SPACE TO ACCESS ONLY THE NON-INF EDGES\n",
    "    input:\n",
    "        current_state:\n",
    "            the current tuple of indices in the grid\n",
    "        action:\n",
    "            any of [0, 1, 2, 3] \n",
    "            taking the directions N, S, W, E respectively\n",
    "\n",
    "    returns:\n",
    "        valid action: the index tuple of the next state\n",
    "        invalid action: None\n",
    "    \"\"\"\n",
    "\n",
    "    if not (0 <= action < 4):\n",
    "        raise ValueError(f\"Invalid action {action}. Must be in [0, 3] range.\")\n",
    "    \n",
    "    x, y = current_cell\n",
    "    \n",
    "    if not (0 <= x < maze.num_rows):\n",
    "        # raise ValueError(f\"Current state {x} out of row range {maze.num_rows}\")\n",
    "        return None\n",
    "    if not (0 <= y < maze.num_columns):\n",
    "        # raise ValueError(f\"Current state {x} out of row range {maze.num_columns}\")\n",
    "        return None\n",
    "    directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "    dx, dy = directions[action]\n",
    "\n",
    "    if not (0 <= x+dx < maze.num_rows):\n",
    "        # raise ValueError(f\"Current state {x} out of row range {maze.num_rows}\")\n",
    "        return None\n",
    "    if not (0 <= y+dy < maze.num_columns):\n",
    "        # raise ValueError(f\"Current state {x} out of row range {maze.num_columns}\")\n",
    "        return None\n",
    "\n",
    "    return (x+dx, y+dy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_state(state, action):\n",
    "    \"\"\"\n",
    "    Uses the get_next_cell function. Easie to use due to the helper functions.\n",
    "    input:\n",
    "        state: \n",
    "            current state\n",
    "        action:\n",
    "            current action\n",
    "    return:\n",
    "        future state\n",
    "    \"\"\"\n",
    "    start_cell = state_to_cell(state)\n",
    "    end_cell = get_next_cell(start_cell, action)\n",
    "    try:\n",
    "        return cell_to_state(end_cell)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next_state(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of all actions that can be taken\n",
    "# N, S, W, E\n",
    "actions = [0, 1, 2, 3]"
   ]
  },
  {
   "source": [
    "q table is desined such that where\n",
    "```q[i][j]``` \n",
    "\n",
    "- i is the state\n",
    "- j is the action that can be taken\n",
    "\n",
    "if you do take the the jth action, using get_next_state(i, j) gives k, the new state\n",
    "k = get_next_state(i, j)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_actions(state):\n",
    "    valid_actions = []\n",
    "    for action in actions:\n",
    "        if get_next_state(state, action):\n",
    "            valid_actions.append(action)\n",
    "    return valid_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16\n[-inf, 0, -inf, 0]\n[0, -inf, -inf, -inf]\n"
     ]
    }
   ],
   "source": [
    "# setup the q table\n",
    "q_table = []\n",
    "\n",
    "for i in range(maze.num_rows):\n",
    "    for j in range(maze.num_columns):\n",
    "        temp = []\n",
    "        for value in maze.grid[i][j].neighbors.values():\n",
    "            # the edges which are walls have value as -inf, \n",
    "            # to discourage any agent trying to go from there\n",
    "            temp.append(-value)\n",
    "        q_table.append(temp)\n",
    "\n",
    "print(len(q_table))\n",
    "print(q_table[0])\n",
    "print(q_table[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(state, action):\n",
    "    return q_table[state][action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all the states\n",
    "for i in range(N*N):\n",
    "    for j in actions:\n",
    "        q_table[i][j] += LEARNING_RATE * (\n",
    "            reward(i)\n",
    "            + DISCOUNT * max([\n",
    "                Q(get_next_state(i, action), action) for action in get_valid_actions(i) \n",
    "            ])\n",
    "            - Q(i, j)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n15\n[0, 2]\n11\n14\n0\n0\n[0, 0, -inf, -inf]\n"
     ]
    }
   ],
   "source": [
    "print(N)\n",
    "state = N*N-1\n",
    "print(state)\n",
    "print(get_valid_actions(state))\n",
    "print(get_next_state(state, 0))\n",
    "print(get_next_state(state, 2))\n",
    "print(Q(11, 0))\n",
    "print(Q(14, 2))\n",
    "print(q_table[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "[Q(get_next_state(N*N-1, action), action) for action in get_valid_actions(N*N-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.21825298639000001, nan, nan, -0.21825298639000001]\n[nan, -0.29701, nan, -0.29701]\n"
     ]
    }
   ],
   "source": [
    "# traverse time\n",
    "while state != "
   ]
  }
 ]
}